# Fullmoon iOS 应用 - 产品与技术规划：本地 AI 引擎

**版本：** 1.1
**日期：** 2025年5月1日
**作者：** GitHub Copilot (生成)

## 1. 愿景

打造一款功能强大、用户友好的 iOS 应用（"Fullmoon"），利用本地 AI 模型的能力，让用户能够直接在设备上执行文本生成、图像创建、查询本地知识库以及利用 AI 代理等任务，确保隐私、离线可用性，并提供与领先的云 AI 服务相媲美的无缝用户体验。

## 2. 核心原则

*   **本地优先：** 优先考虑设备端处理，以保护隐私、提高速度（模型加载后）并实现离线访问。
*   **简洁清晰：** 尽管底层复杂，仍保持干净、直观、整洁的用户界面。遵循 iOS 人机界面指南。
*   **统一体验：** 确保所有功能（聊天、图像生成、知识库、代理）采用一致的设计语言和交互模式。
*   **性能透明：** 清晰传达模型下载状态、处理时间以及潜在的资源使用情况。在适当情况下提供用户控制选项。
*   **迭代开发：** 从核心功能开始，根据用户反馈和技术可行性逐步增加功能。
*   **模块化：** 设计架构以便轻松集成不同的本地模型（LLM、扩散模型等），特别是那些针对移动设备优化后的模型。

## 3. 当前技术基础

基于现有代码分析，Fullmoon iOS 应用已经具备以下技术基础：

* **MLX 推理框架**：使用 Apple 的 MLX 库为基础的推理引擎，适用于 iOS 设备上的高效模型执行。
* **模型支持**：已集成多种小型高效 LLM，包括：
  * Llama 3.2 (1B 和 3B 版本)
  * DeepSeek R1 系列
  * Qwen3 系列 (0.6B, 1.7B, 4B 等不同规格)
* **量化支持**：已支持 4-bit、8-bit 和 BFloat16 等不同量化级别，在保持模型质量的同时优化性能和存储。
* **基础对话系统**：支持基本的聊天功能，包括系统提示和上下文管理。
* **应用架构**：使用 SwiftUI 构建现代化、响应式 UI。

## 4. 功能路线图（迭代方法）

此路线图基于已有基础上展开，遵循渐进式开发策略，优先利用已有的开源技术。

### 迭代 1：优化核心文本聊天（已部分实现）

*   **目标：** 完善和优化基于本地 LLM 的文本聊天功能。
*   **功能：**
    *   **已实现：** 
      * 基础 LLM 集成（Llama, DeepSeek, Qwen 等模型）
      * 简单的单会话聊天界面
      * 基础模型管理
    *   **待优化：**
      * 改进交互模型，实现思考状态反馈（已有代码中的 `isThinking` 功能）
      * 扩展系统提示模板库，以优化各种场景下的对话效果
      * 添加少量示例对话以帮助新用户理解功能
*   **技术方案：** 
    * 继续使用 MLX 框架，优化模型加载和推理流程
    * 添加本地模型缓存策略，减少重复下载
    * 实现更精细的内存管理，监控 GPU 内存使用

### 迭代 2：增强聊天与模型管理

*   **目标：** 改善聊天体验并提供更健壮的模型处理。
*   **功能：**
    *   支持多聊天会话（能够创建、重命名、删除不同的对话）。
    *   改进聊天 UI：支持 Markdown 渲染响应、代码块高亮、消息复制功能。
    *   增强模型管理：
        *   浏览可用的本地模型（显示大小、描述、特点、适用场景）
        *   并行/队列下载多个模型
        *   删除已下载的模型
        *   更清晰的下载/加载问题错误处理
    *   推理速度和内存使用的性能优化
    *   聊天会话内的基本上下文管理
*   **技术方案：**
    * 使用 Swift 的 `ObservableObject` 或 `@Observable` 宏进行状态管理
    * 集成 [Highlightr](https://github.com/raspu/Highlightr) 用于代码高亮
    * 使用 [Down](https://github.com/johnxnguyen/Down) 或 [MarkdownUI](https://github.com/gonzalezreal/MarkdownUI) 进行高效的 Markdown 渲染
    * 实现基于 URLSession 的后台下载队列管理

### 迭代 3：本地图像生成

*   **目标：** 引入设备端图像生成能力。
*   **功能：**
    *   集成一个本地图像生成模型（移动优化的 Stable Diffusion 变体）。
    *   专门的图像生成 UI 部分。
    *   将生成的图像保存到设备照片库的功能。
*   **技术方案：**
    * 使用开源的 [Apple/ml-stable-diffusion](https://github.com/apple/ml-stable-diffusion) 作为图像生成基础
    * 考虑集成以下优化版本:
      * Tiny SD (极小版本 Stable Diffusion)
      * [SD-Turbo](https://huggingface.co/stabilityai/sd-turbo) (单步扩散模型)
      * 使用 CoreML 编译后的模型减少内存消耗和提升速度
    * 实现渐进式预览，让用户在生成过程中看到图像逐步构建

### 迭代 4：本地知识库 (RAG)

*   **目标：** 允许用户与自己的本地文档进行聊天。
*   **功能：**
    *   提供导入用户文档的机制（初期支持纯文本，后续支持 PDF）。
    *   为导入的文档进行本地索引/嵌入生成处理。
    *   与聊天界面集成：
        *   提供为聊天会话选择特定知识库来源的选项。
        *   实现检索增强生成 (RAG)，在 LLM 响应中使用文档上下文。
*   **技术方案：**
    * 利用 [Swift-MXLangChain](https://github.com/ml-explore/swift-mxlangchain) 实现 RAG 系统
    * 使用 Apple 的 NaturalLanguage 框架进行文本分析和处理
    * 集成 [FAISS](https://github.com/facebookresearch/faiss) 的 Swift 绑定或使用 [USSearch](https://github.com/unum-cloud/usearch) 作为向量搜索引擎
    * 利用 [E5-small](https://huggingface.co/intfloat/e5-small) 等小型嵌入模型，确保嵌入生成过程轻量高效

### 迭代 5：基础 Agent 功能

*   **目标：** 为特定任务引入初步的 AI 代理能力。
*   **功能：**
    *   定义一组简单的、预定义的代理任务（总结文本、提取要点、翻译文本等）。
    *   在聊天界面内集成代理调用。
    *   允许用户为代理任务提供输入。
*   **技术方案：**
    * 基于现有的"思考"功能（代码中已有 `isThinking` 状态）扩展 Agent 能力
    * 使用 JSON 格式定义工具和任务，实现标准化的 Agent 接口
    * 集成 ChatML 格式支持，以便更好地处理工具调用和响应
    * 借鉴 [CrewAI](https://github.com/crewai/crewai) 的设计思路，为本地 Agent 系统构建基础框架

## 5. 核心技术栈规划

### LLM 框架与推理引擎

* **主推理引擎：** MLX（已实现）
* **辅助引擎选项：**
  * [llama.cpp](https://github.com/ggerganov/llama.cpp) - 用于支持更多模型格式 
  * [CoreML](https://developer.apple.com/documentation/coreml) - 用于针对 Apple 硬件优化的模型

### 模型支持扩展计划

* **文本模型增强：**
  * 考虑添加 [Phi-3](https://huggingface.co/microsoft/phi-3-mini-4k-instruct) 系列小型模型
  * 探索 [MiniCPM](https://github.com/OpenBMB/MiniCPM) 等高效小型模型
  * 为特定任务定制微调小型专用模型

* **图像生成模型：**
  * SD-Turbo（单步扩散）
  * Tiny SD（更小版本）
  * [PixArt-Alpha](https://github.com/PixArt-alpha/PixArt-alpha)（如有轻量版）
  
* **嵌入模型：**
  * E5-small
  * MiniLM-L6
  * Nomic-Embed-Text（如有轻量版）

### 性能优化策略

* **模型量化：** 继续支持 2-bit、4-bit、8-bit、BFloat16 等量化级别
* **缓存优化：** 实现智能缓存系统，根据使用频率管理模型加载/卸载
* **批处理：** 优化输入批处理以提高吞吐量
* **硬件利用：** 充分利用 Apple Neural Engine (ANE)，针对不同芯片优化模型加载策略

## 6. UI/UX 设计规划

*   **统一设计语言：** 开发专属的 Fullmoon 设计系统，确保所有功能的视觉和交互一致性
*   **引导式体验：** 优化首次使用流程，增加任务指引和功能发现
*   **状态反馈：** 增强视觉反馈系统，特别是对于长时间运行的任务（如模型下载、推理过程）
*   **高级定制：** 允许用户自定义界面布局、主题和交互方式
*   **原生集成：** 深度整合 iOS 系统特性，如分享扩展、焦点模式和快捷指令

## 7. 开发与实施时间表

| 迭代阶段 | 预计时长 | 主要开发目标 |
|---------|---------|------------|
| 迭代 1 | 2-3 周 | 优化核心文本聊天功能，改进现有代码 |
| 迭代 2 | 3-4 周 | 增强多会话管理和模型管理界面 |
| 迭代 3 | 4-5 周 | 实现基础图像生成功能 |
| 迭代 4 | 5-6 周 | 开发本地知识库集成系统 |
| 迭代 5 | 4-5 周 | 构建基础 Agent 功能框架 |

## 8. 关键技术挑战与解决方案

* **内存管理：** 模型大小与设备内存限制的平衡
  * 解决方案：实现动态模型加载/卸载，分层执行策略
  
* **电池消耗：** 本地推理对电池寿命的影响
  * 解决方案：批处理优化，模型选择智能化，后台任务管理
  
* **用户体验连贯性：** 模型加载与执行延迟可能破坏体验流畅性
  * 解决方案：预加载常用模型，UI反馈优化，结果缓存策略
  
* **存储管理：** 多模型并存对设备存储空间的压力
  * 解决方案：云端同步可选功能，智能本地存储管理，模型生命周期管理

## 9. 结论

Fullmoon iOS 应用有潜力成为本地 AI 能力的典范，通过站在开源社区的肩膀上，我们可以构建一个功能强大且高效的应用。每个迭代都将带来新的能力，同时保持应用的高性能和用户友好特性。本规划提供了明确的技术路线图，确保开发团队能够有序地实现这一愿景。

最终目标是打造一款让用户惊叹的应用，它不仅展示了本地 AI 的潜力，还为用户提供了一个实用、安全且令人愉悦的工具，真正体现 AI 赋能个人设备的未来。
